"""
    Created on March 2015
    @author: hussein
"""
import pandas as pd
import numpy as np
from sklearn import cross_validation
from sklearn.metrics import make_scorer
from sklearn.grid_search import GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor

def my_custom_loss_func(ground_truth, predictions):

    diff = (np.log(ground_truth+1) - np.log(predictions+1))**2
    return np.sqrt(np.mean(diff))

my_custom_scorer = make_scorer(my_custom_loss_func, greater_is_better=False)

gridR = GridSearchCV(estimator=GradientBoostingRegressor(n_estimators=50,
                                                         random_state=42,
                                                         verbose=1), 
                    param_grid={"max_depth": [9],
                                "learning_rate": [0.125],
                                "n_estimators": [50]}, 
                    scoring=my_custom_scorer, 
                    cv=3, n_jobs=-1)

gridC = GridSearchCV(estimator=GradientBoostingRegressor(n_estimators=50,
                                                         random_state=42,
                                                         verbose=1), 
                    param_grid={"max_depth": [9],
                                "learning_rate": [0.125],
                                "n_estimators": [50]}, 
                    scoring=my_custom_scorer, 
                    cv=3, n_jobs=-1)

# Please update the absolute path of the project files here
absPath = '/home/hussein/Documents/bikes/'

# Here we define a function for preprocessing the data


def prepros(t):
    #  Adding date feilds
    datt = pd.to_datetime(t['datetime'])
    t['datetime'] = datt
    t['hour'] = t.datetime.apply(lambda x: x.hour)
    t['month'] = t.datetime.apply(lambda x: x.month)
    t['day'] = t.datetime.apply(lambda x: x.day)
    t['year'] = t.datetime.apply(lambda x: x.year)
    t['dayOfWeek'] = t.datetime.apply(lambda x: x.weekday())
    # calculating the Dew_Point temp from humidity and temp
    temp = np.array(t['temp'].values)
    humid = np.array(t['humidity'].values)
    t['dew'] = np.power(humid, (1.0/8.0))*(112+0.9*temp) + 0.1*temp - 112

    td = t.values[:, 1:]  # geting all fields except the datetime feild
    pddata = td.astype(dtype=float)  # transform the values into float numbers
    return pddata

# read training data
train = pd.read_csv('/home/hussein/Documents/bikes/train.csv')
ppdata = prepros(train)  # calling the data preprocessing for the training data

# taking out the predicted fields (Registered, casual and count)
tdata = ppdata[:, (0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16)]

# Spliting the data for Cross Validation

a_train, a_test = cross_validation.train_test_split(ppdata, test_size=0.3)
tdtrain = a_train[:, (0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16)]
tdtest = a_test[:, (0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16)]

# Define scoring/error function that matching the scoring of the competition

# GradientBoostingRegressor with SearchGrid using the new defined scoring function

# for Registered
# learning the registered count model
gridR.fit(tdtrain, a_train[:, 9])
scorGSRFR = gridR.score(tdtest, a_test[:, 9])  # Measureing the scoring on the test data
# Best parameters and scoring the found model (Registered)
bestPR = gridR.best_params_
scoreDictR = gridR.grid_scores_

# for Casual
gridC.fit(tdtrain, a_train[:, 8])
scorGSRFC = gridC.score(tdtest, a_test[:, 8])  # Measureing the scoring on the test data
# Best parameters and scoring the found model (Casual)
bestPC = gridC.best_params_
scoreDictC = gridC.grid_scores_

# read test data
test = pd.read_csv(absPath+'test.csv')
tsdata = prepros(test)

tmpR = gridR.predict(tsdata[:, 0:])

# tmpresult Casual
tmpC = gridC.predict(tsdata[:, 0:])


# Adding R and C for final results
tmp = tmpR + tmpC
tmpresult = tmp.astype(dtype=int)

# read and write submittion
subm = pd.read_csv(absPath+'sampleSubmission.csv')
subm['count'] = tmpresult

subm.to_csv(absPath+'sub2015.csv', index=False)
